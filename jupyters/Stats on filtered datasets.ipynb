{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "\n",
    "class OrderedCounter(Counter, OrderedDict):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset, mapping):\n",
    "    mapped_dataset = []\n",
    "    unmapped_dataset = []\n",
    "    \n",
    "    for d in tqdm(dataset):\n",
    "        only_mapped = True\n",
    "        new_types = []\n",
    "        non_mapped_types = []\n",
    "        \n",
    "        for t in d['y_str']:\n",
    "            if mapping[t]:\n",
    "                for ty in mapping[t]:\n",
    "                    new_types.append(ty)\n",
    "            else:\n",
    "                only_mapped = False\n",
    "                non_mapped_types.append(t)\n",
    "        \n",
    "        if new_types:\n",
    "            mapped_d = {k:v for k, v  in d.items() if k != 'y_str'}\n",
    "            mapped_d['y_str'] = [t for t in new_types]\n",
    "            mapped_d['original_types'] = [t for t in new_types]\n",
    "            mapped_d['original_types'].extend(non_mapped_types)\n",
    "            \n",
    "            mapped_dataset.append(mapped_d)\n",
    "        \n",
    "        if not only_mapped:\n",
    "            unmapped_d = {k:v for k, v  in d.items() if k != 'y_str'}\n",
    "            unmapped_d['y_str'] = [t for t in new_types]\n",
    "            unmapped_d['y_str'].extend(non_mapped_types)\n",
    "            unmapped_dataset.append(unmapped_d)\n",
    "    return mapped_dataset, unmapped_dataset\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def types_stats(dataset):\n",
    "    unique_types = set()\n",
    "    total_types = 0\n",
    "    for d in tqdm(dataset):\n",
    "        unique_types = unique_types.union(set(d['y_str']))\n",
    "        total_types += len(d['y_str'])\n",
    "    return unique_types, total_types / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partially_translate_dataset(dataset, trans_dict):\n",
    "    new_dataset = []\n",
    "    for d in tqdm(dataset):\n",
    "        new_types = []\n",
    "        for t in d['y_str']:\n",
    "            for new_t in trans_dict[t]:\n",
    "                new_types.append(new_t)\n",
    "        new_dataset.append({k: v for k, v in d.items() if k != 'y_str'})\n",
    "        new_dataset[-1]['y_str'] = [t for t in new_types]\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/datahdd/vmanuel/entity_typing_all_datasets/data/entity_typing_original_datasets/ontonotes/g_train_tree.json', 'r') as inp:\n",
    "    train_lines = [json.loads(t) for t in inp.readlines()]\n",
    "with open('/datahdd/vmanuel/entity_typing_all_datasets/data/entity_typing_original_datasets/ontonotes/g_dev_tree.json', 'r') as inp:\n",
    "    dev_lines = [json.loads(t) for t in inp.readlines()]\n",
    "with open('/datahdd/vmanuel/entity_typing_all_datasets/data/entity_typing_original_datasets/ontonotes/g_test_tree_lines.json', 'r') as inp:\n",
    "    test_lines = [json.loads(t) for t in inp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ontonotes_mappings = {'FIGER': defaultdict(list), 'choi': defaultdict(list), 'BBN': defaultdict(list)}\n",
    "\n",
    "with open('/datahdd/vmanuel/entity_typing_all_datasets/data/entity_typing_original_datasets/OntoNotes_mappings.csv', 'r') as inp:\n",
    "    lines = [l.replace('\\n', '') for l in inp.readlines()]\n",
    "    for l in lines[1:]:\n",
    "        splitted = l.split(',')\n",
    "        if splitted[1] != '-':\n",
    "            ontonotes_mappings['BBN'][splitted[0]].append(splitted[1])\n",
    "        if splitted[2] != '-':\n",
    "            ontonotes_mappings['FIGER'][splitted[0]].append(splitted[2])\n",
    "        if splitted[3] != '-':\n",
    "            ontonotes_mappings['choi'][splitted[0]].append(splitted[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/datahdd/vmanuel/entity_typing_all_datasets/data/ontology/onto_ontology.txt', 'r') as inp:\n",
    "    types = set([l.replace('\\n', '') for l in inp.readlines()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onto Filtered with BBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = ontonotes_mappings['BBN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_translation_dict = defaultdict(list)\n",
    "\n",
    "for t in types:\n",
    "    if mapping[t]:\n",
    "        for i, m in enumerate(mapping[t]):\n",
    "            partially_translation_dict[t].append(m)\n",
    "    else:\n",
    "        partially_translation_dict[t].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [00:01<00:00, 148868.01it/s]\n"
     ]
    }
   ],
   "source": [
    "partially_translated_dataset = partially_translate_dataset(train_lines, partially_translation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [00:03<00:00, 75771.21it/s] \n"
     ]
    }
   ],
   "source": [
    "mapped_train, unmapped_train = filter_dataset(train_lines, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [00:00<00:00, 381703.57it/s]\n",
      "100%|██████████| 251039/251039 [00:00<00:00, 496034.48it/s]\n",
      "100%|██████████| 229362/229362 [00:00<00:00, 652599.54it/s]\n",
      "100%|██████████| 180298/180298 [00:00<00:00, 341603.44it/s]\n"
     ]
    }
   ],
   "source": [
    "original_types, original_txe = types_stats(train_lines)\n",
    "translated_types, translated_txe = types_stats(partially_translated_dataset)\n",
    "mapped_types, mapped_txe = types_stats(mapped_train)\n",
    "unmapped_types, unmapped_txe = types_stats(unmapped_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_mapped_types = [t for t in types if mapping[t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped types from Onto to BBN: 31 on 89, 0.35\n"
     ]
    }
   ],
   "source": [
    "print('mapped types from Onto to BBN: {} on {}, {:.2f}'.format(len(list_of_mapped_types), \n",
    "                                                               len(types),\n",
    "                                                               len(list_of_mapped_types)/len(original_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto -> bbn |    original dataset     |original traduced dataset|     mapped dataset      |    unmapped dataset     \n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "  mentions  |         251039          |         251039          |         229362          |         180298          \n",
      "   types    |           89            |           87            |           29            |           87            \n",
      " avg_types  |          2.79           |          2.79           |          1.55           |          3.19           \n"
     ]
    }
   ],
   "source": [
    "print('{:^12}|{:^25}|{:^25}|{:^25}|{:^25}'.format('onto -> bbn', 'original dataset', 'original traduced dataset', 'mapped dataset', 'unmapped dataset'))\n",
    "print('{:-^12}-{:-^25}-{:-^25}-{:-^25}-{:-^25}'.format('', '', '', '', ''))\n",
    "print('{:^12}|{:^25}|{:^25}|{:^25}|{:^25}'.format('mentions', len(train_lines), len(partially_translated_dataset), len(mapped_train), len(unmapped_train)))\n",
    "print('{:^12}|{:^25}|{:^25}|{:^25}|{:^25}'.format('types', len(original_types), len(translated_types), len(mapped_types), len(unmapped_types)))\n",
    "print('{:^12}|{:^25.2f}|{:^25.2f}|{:^25.2f}|{:^25.2f}'.format('avg_types', original_txe, translated_txe, mapped_txe, unmapped_txe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute statistics on unmapped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_types = translated_types.difference(unmapped_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'missing types in unmapped dataset: 0 on 87'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"missing types in unmapped dataset: {} on {}\".format(len(missing_types), len(translated_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = [t for u in unmapped_train for t in u['y_str']]\n",
    "unmapped_c = dict(sorted(Counter(all_types).items(), key = lambda x:x[1], reverse=True))\n",
    "\n",
    "all_types = [t for u in partially_translated_dataset for t in u['y_str']]\n",
    "translated_c = dict(sorted(Counter(all_types).items(), key = lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Class:  unmapped occ   |    total occ   \n",
      "----------------------------------------------------------------------------\n",
      "                                  /other:           92208 | 92208          \n",
      "                                 /PERSON:           83228 | 89531          \n",
      "                           /person/title:           37970 | 37970          \n",
      "                          /person/artist:           35496 | 35496          \n",
      "                   /person/artist/author:           28998 | 28998          \n",
      "                           /ORGANIZATION:           23539 | 44070          \n",
      "                /person/political_figure:           21455 | 21455          \n",
      "                            /WORK_OF_ART:           17635 | 17635          \n",
      "                    /person/artist/actor:           16404 | 16404          \n",
      "                               /LOCATION:           12407 | 60583          \n",
      "               /ORGANIZATION/CORPORATION:           11792 | 21680          \n",
      "                                  /EVENT:           11655 | 11655          \n",
      "                           /other/health:           11620 | 11620          \n",
      "                /ORGANIZATION/GOVERNMENT:           11279 | 13978          \n",
      "                        /person/military:           10472 | 10472          \n",
      "                     /other/supernatural:           10334 | 10334          \n",
      "                       /WORK_OF_ART/BOOK:           10238 | 10238          \n",
      "                                /PRODUCT:            9518 | 9518           \n",
      "                     /location/structure:            8955 | 8955           \n",
      "              /organization/company/news:            8295 | 8295           \n",
      "                                /DISEASE:            7641 | 7641           \n",
      "                     /other/living_thing:            6812 | 6812           \n",
      "                         /other/internet:            4605 | 4605           \n",
      "                        /other/body_part:            4563 | 4563           \n",
      "                       /other/scientific:            4395 | 4395           \n",
      "                         /other/currency:            4165 | 4165           \n",
      "                              /EVENT/WAR:            4142 | 4142           \n",
      "                         /SUBSTANCE/DRUG:            3981 | 3981           \n",
      "                       /WORK_OF_ART/SONG:            3853 | 3853           \n",
      "                         /SUBSTANCE/FOOD:            3762 | 3762           \n",
      "                /person/religious_leader:            3601 | 3601           \n",
      "                  /organization/military:            3460 | 3460           \n",
      "                            /GPE/COUNTRY:            2725 | 22749          \n",
      "                 /ORGANIZATION/RELIGIOUS:            2658 | 2658           \n",
      "                    /person/artist/music:            2651 | 2651           \n",
      "                    /other/event/holiday:            2487 | 2487           \n",
      "                       /WORK_OF_ART/PLAY:            2482 | 2482           \n",
      "                         /other/heritage:            2470 | 2470           \n",
      "                               /LANGUAGE:            2363 | 2363           \n",
      "                 /other/product/software:            2305 | 2305           \n",
      "                                 /ANIMAL:            2180 | 2180           \n",
      "         /organization/company/broadcast:            1936 | 1936           \n",
      "                     /organization/music:            1745 | 1745           \n",
      "                 /person/artist/director:            1588 | 1588           \n",
      "                           /person/legal:            1569 | 1569           \n",
      "                         /person/athlete:            1564 | 1564           \n",
      "                    /other/art/broadcast:            1553 | 1553           \n",
      "                     /location/geography:            1332 | 1332           \n",
      "           /other/event/natural_disaster:            1179 | 1179           \n",
      "                   /other/event/election:            1078 | 1078           \n",
      "                    /other/event/protest:            1012 | 1012           \n",
      "       /location/geography/body_of_water:             985 | 985            \n",
      "               /organization/sports_team:             887 | 887            \n",
      "                        /PRODUCT/VEHICLE:             837 | 837            \n",
      "                     /location/celestial:             790 | 790            \n",
      "                 /ORGANIZATION/POLITICAL:             677 | 2055           \n",
      "                         /PRODUCT/WEAPON:             604 | 604            \n",
      "               /other/sports_and_leisure:             559 | 559            \n",
      "                                    /LAW:             427 | 427            \n",
      "            /organization/stock_exchange:             415 | 415            \n",
      "                   /organization/transit:             342 | 342            \n",
      "             /organization/sports_league:             318 | 318            \n",
      "                       /location/transit:             236 | 236            \n",
      "               /ORGANIZATION/EDUCATIONAL:             224 | 3156           \n",
      "                  /location/transit/road:             205 | 205            \n",
      "             /location/structure/theater:             195 | 195            \n",
      "              /location/geography/island:             190 | 190            \n",
      "                          /person/doctor:             152 | 152            \n",
      "            /location/geography/mountain:             150 | 150            \n",
      "                       /FACILITY/AIRPORT:             141 | 141            \n",
      "          /location/structure/restaurant:             113 | 113            \n",
      "     /location/structure/sports_facility:             105 | 105            \n",
      "                            /other/award:              98 | 98             \n",
      "                 /other/product/computer:              96 | 96             \n",
      "               /location/geograpy/island:              92 | 92             \n",
      "                      /location/geograpy:              92 | 92             \n",
      "                          /location/park:              89 | 89             \n",
      "                  /ORGANIZATION/HOSPITAL:              85 | 85             \n",
      "    /other/language/programming_language:              82 | 82             \n",
      "                           /person/coach:              79 | 79             \n",
      "               /other/event/sports_event:              76 | 76             \n",
      "                     /ORGANIZATION/HOTEL:              49 | 49             \n",
      "                   /other/event/accident:              34 | 34             \n",
      "                        /FACILITY/BRIDGE:              26 | 26             \n",
      "                               /GPE/CITY:              20 | 14402          \n",
      "             /other/product/mobile_phone:              20 | 20             \n",
      "               /location/transit/railway:               5 | 5              \n"
     ]
    }
   ],
   "source": [
    "print('{:>40}: {:^15} | {:^15}'.format('Class', 'unmapped occ', 'total occ'))\n",
    "print('{:->40}---{:-^15}---{:-^15}'.format('', '', ''))\n",
    "for k, v in c.items():\n",
    "    print('{:>40}: {:>15} | {:<15}'.format(k, v, translated_c[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onto Filtered with FIGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = ontonotes_mappings['FIGER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_translation_dict = defaultdict(list)\n",
    "\n",
    "for t in types:\n",
    "    if mapping[t]:\n",
    "        for i, m in enumerate(mapping[t]):\n",
    "            partially_translation_dict[t].append(m)\n",
    "    else:\n",
    "        partially_translation_dict[t].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [00:02<00:00, 101245.77it/s]\n"
     ]
    }
   ],
   "source": [
    "partially_translated_dataset = partially_translate_dataset(train_lines, partially_translation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [00:02<00:00, 99606.12it/s] \n"
     ]
    }
   ],
   "source": [
    "mapped_train, unmapped_train = filter_dataset(train_lines, mapping, partially_translation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [00:00<00:00, 400177.06it/s]\n",
      "100%|██████████| 251039/251039 [00:00<00:00, 482347.79it/s]\n",
      "100%|██████████| 243909/243909 [00:00<00:00, 488785.95it/s]\n",
      "100%|██████████| 107317/107317 [00:00<00:00, 298855.17it/s]\n"
     ]
    }
   ],
   "source": [
    "original_types, original_txe = types_stats(train_lines)\n",
    "translated_types, translated_txe = types_stats(partially_translated_dataset)\n",
    "mapped_types, mapped_txe = types_stats(mapped_train)\n",
    "unmapped_types, unmapped_txe = types_stats(unmapped_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_mapped_types = [t for t in types if mapping[t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped types from Onto to BBN: 75 on 89, 0.84\n"
     ]
    }
   ],
   "source": [
    "print('mapped types from Onto to BBN: {} on {}, {:.2f}'.format(len(list_of_mapped_types), \n",
    "                                                               len(types),\n",
    "                                                               len(list_of_mapped_types)/len(original_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto -> bbn |    original dataset     |original traduced dataset|     mapped dataset      |    unmapped dataset     \n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "  mentions  |         251039          |         251039          |         243909          |         107317          \n",
      "   types    |           89            |           88            |           74            |           80            \n",
      " avg_types  |          2.79           |          2.89           |          2.40           |          3.36           \n"
     ]
    }
   ],
   "source": [
    "print('{:^12}|{:^25}|{:^25}|{:^25}|{:^25}'.format('onto -> bbn', 'original dataset', 'original traduced dataset', 'mapped dataset', 'unmapped dataset'))\n",
    "print('{:-^12}-{:-^25}-{:-^25}-{:-^25}-{:-^25}'.format('', '', '', '', ''))\n",
    "print('{:^12}|{:^25}|{:^25}|{:^25}|{:^25}'.format('mentions', len(train_lines), len(partially_translated_dataset), len(mapped_train), len(unmapped_train)))\n",
    "print('{:^12}|{:^25}|{:^25}|{:^25}|{:^25}'.format('types', len(original_types), len(translated_types), len(mapped_types), len(unmapped_types)))\n",
    "print('{:^12}|{:^25.2f}|{:^25.2f}|{:^25.2f}|{:^25.2f}'.format('avg_types', original_txe, translated_txe, mapped_txe, unmapped_txe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annot_id': '2',\n",
       " 'left_context_token': ['Usually'],\n",
       " 'mention_span': 'directors',\n",
       " 'mention_span_tree': [{'dep': 'ROOT',\n",
       "   'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'director',\n",
       "   'pos': 'NOUN',\n",
       "   'shape': 'xxxx',\n",
       "   'tag': 'NNS',\n",
       "   'text': 'directors'}],\n",
       " 'original_types': ['/PERSON', '/person/title'],\n",
       " 'right_context_token': [',',\n",
       "  'otherwise',\n",
       "  ',',\n",
       "  'they',\n",
       "  'have',\n",
       "  'beards',\n",
       "  'and',\n",
       "  'very',\n",
       "  'long',\n",
       "  'hair',\n",
       "  ',',\n",
       "  'or',\n",
       "  'otherwise',\n",
       "  'they',\n",
       "  'shave',\n",
       "  'their',\n",
       "  'heads',\n",
       "  '.'],\n",
       " 'y': [4, 1],\n",
       " 'y_str': ['/PERSON'],\n",
       " 'y_type': [0, 0],\n",
       " 'y_type_str': ['KB', 'KB']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
